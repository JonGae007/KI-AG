{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1903ee05",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576c2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "os.environ[\"NO_PROXY\"] = \"localhost,127.0.0.1\"\n",
    "os.environ[\"USER_AGENT\"] = \"myagent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f249d",
   "metadata": {},
   "source": [
    "# LLM Initialisierung mit Beispiel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f73c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Vorteile eines lokalen Large Language Models (LLM)\n",
      "\n",
      "| # | Vorteil | Warum das wichtig ist | Praktische Beispiele |\n",
      "|---|---------|----------------------|----------------------|\n",
      "| 1 | **Datenschutz & Vertraulichkeit** | Alle Daten bleiben im Unternehmensnetzwerk – keine sensiblen Infos gehen an Dritte. | Ein Finanzinstitut kann Kundendaten für Kreditentscheidungen analysieren, ohne die Daten an einen Cloud‑Provider zu senden. |\n",
      "| 2 | **Rechtliche & regulatorische Compliance** | Einhaltung von DSGVO, HIPAA, ISO‑Normen etc. ist einfacher, wenn keine Daten das Land verlassen. | Ein Gesundheitsdienstleister kann Patientenberichte verarbeiten, ohne sich um Export‑Beschränkungen sorgen zu müssen. |\n",
      "| 3 | **Niedrigere Latenz & höhere Performance** | Lokale Modelle liefern Antworten in Millisekunden – ideal für Echtzeit‑Anwendungen (Chat‑Bots, Assistenz‑Apps). | Ein Call‑Center‑System beantwortet Kundenanfragen sofort, ohne Netzwerk‑Round‑Trips. |\n",
      "| 4 | **Kostenkontrolle** | Nach dem einmaligen Kauf oder der Lizenz gibt es keine fortlaufenden API‑Kosten. | Ein Start‑Up kann ein Modell für interne Projekte nutzen, ohne monatlich Hunderte Euro zu zahlen. |\n",
      "| 5 | **Unabhängigkeit & Vendor‑Lock‑In** | Keine Abhängigkeit von Cloud‑Anbietern, die Preise erhöhen oder Dienste einstellt. | Ein Unternehmen kann das Modell jederzeit auf einen anderen Server verschieben oder selbst weiterentwickeln. |\n",
      "| 6 | **Anpassung & Fein‑Tuning** | Das Modell lässt sich exakt an branchenspezifische Terminologie, Stil und Daten anpassen. | Ein Rechtsamt trainiert das LLM mit internen Urteilen, um juristische Dokumente automatisch zu prüfen. |\n",
      "| 7 | **Offline‑Funktionalität** | Keine Internetverbindung nötig – nützlich in Gebieten mit schlechter Konnektivität oder bei Sicherheitsrichtlinien. | Ein Feldarbeiter kann im Wald ein medizinisches Diagnose‑Tool nutzen, ohne Online‑Zugang. |\n",
      "| 8 | **Schnellere Iteration** | Entwickler können Modelle sofort testen, neue Features einbauen und in kurzer Zeit Feedback erhalten. | Ein Entwicklungs­team kann neue Sprach‑Features in einer Woche integrieren, anstatt Tage für Cloud‑Rechenzeit zu warten. |\n",
      "| 9 | **Mehr Transparenz & Kontrolle** | Die Architektur, Gewichte und Logfiles sind komplett einsehbar. | Ein Auditor kann prüfen, ob das Modell keine Bias‑Gefahren birgt, indem er die Trainingsdaten & Gewichtungen einsehen kann. |\n",
      "|10 | **Skalierbarkeit innerhalb des Unternehmens** | Modelle können auf lokalen GPUs, TPUs oder sogar Edge‑Geräten ausgeführt werden. | Ein Produktions‑Cluster startet das Modell in mehreren Rechenzentren, um Lastspitzen zu decken. |\n",
      "\n",
      "---\n",
      "\n",
      "#### Kurz gesagt:\n",
      "\n",
      "Ein lokales LLM liefert **Sicherheit, Kontrolle, Kosten‑Effizienz, niedrige Latenz und volle Anpassbarkeit** – alles ohne die Abhängigkeit von externen Cloud‑Anbietern. Gerade für Unternehmen, die mit sensiblen Daten arbeiten, die hohe Compliance‑Standards erfüllen müssen oder in Bereichen mit eingeschränkter Internetverbindung agieren, ist ein lokales Modell oft die optimale Lösung.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:20b-cloud\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"Du bist ein hilfreicher Assistent.\"),\n",
    "    (\"human\", \"Erkläre mir die Vorteile eines lokalen LLM.\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cb08a",
   "metadata": {},
   "source": [
    "# Embedding Modell Initialisierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36f0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46ef6d32",
   "metadata": {},
   "source": [
    "# Vektordatenbank Initialisierung\n",
    "\n",
    "### Eine Collection für eine Website und eine für ein PDF-Dokument erstellen. Anschließend Collections anzeigen lassen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cf99ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2619444",
   "metadata": {},
   "source": [
    "### Optional: Vorherige Sammlung löschen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(collection_name=name_der_sammlung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43b26fa",
   "metadata": {},
   "source": [
    "# Website laden und Text extrahieren (Website)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280a1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ed2a4f",
   "metadata": {},
   "source": [
    "### Text in Chunks aufteilen (Website)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608a81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22038277",
   "metadata": {},
   "source": [
    "### Chunks in Vektordatenbank speichern (Website)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4f564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b521c95b",
   "metadata": {},
   "source": [
    "# PDF laden und Text extrahieren (PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e776561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65638b14",
   "metadata": {},
   "source": [
    "### Text in Chunks aufteilen (PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fb9913d",
   "metadata": {},
   "source": [
    "### Chunks in Vektordatenbank speichern (PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5708fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3958c65d",
   "metadata": {},
   "source": [
    "# LLM mit Retrieval Augmented Generation verwenden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e51ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b6713ee",
   "metadata": {},
   "source": [
    "### Website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ce6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d25d24",
   "metadata": {},
   "source": [
    "### PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768296bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
